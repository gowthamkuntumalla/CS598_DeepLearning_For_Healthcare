{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from config import Config\n",
    "from patient_data_reader import PatientReader\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Number of units in the hidden (recurrent) layer\n",
    "N_HIDDEN = 200\n",
    "# Number of training sequences in each batch\n",
    "\n",
    "# All gradients above this will be clipped\n",
    "GRAD_CLIP = 100\n",
    "# How often should we check the output?\n",
    "EPOCH_SIZE = 100\n",
    "# Number of epochs to train the net\n",
    "num_epochs = 6\n",
    "\n",
    "MAX_LENGTH = 300\n",
    "\n",
    "# FLAGS.vocab_size = 619\n",
    "\n",
    "\n",
    "\n",
    "N_BATCH = 128 # 128, 32, 1\n",
    "\n",
    "EMBEDSIZE = 100\n",
    "N_TOPICS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<config.Config at 0x19f544be2e0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class Config:\n",
    "#     \"\"\"feel free to play with these hyperparameters during training\"\"\"\n",
    "#     dataset = \"resource\"  # change this to the right data name\n",
    "#     data_path = \"%s\" % dataset\n",
    "#     checkpoint_dir = \"checkpoint\"\n",
    "#     decay_rate = 0.95\n",
    "#     decay_step = 1000\n",
    "#     n_topics = 50\n",
    "#     learning_rate = 0.00002\n",
    "#     vocab_size = 619\n",
    "#     n_stops = 22 \n",
    "#     lda_vocab_size = vocab_size - n_stops\n",
    "#     n_hidden = 200\n",
    "#     n_layers = 2\n",
    "#     projector_embed_dim = 100\n",
    "#     generator_embed_dim = n_hidden\n",
    "#     dropout = 1.0\n",
    "#     max_grad_norm = 1.0 #for gradient clipping\n",
    "#     total_epoch = 5\n",
    "#     init_scale = 0.075\n",
    "#     threshold = 0.5 #probability cut-off for predicting label to be 1\n",
    "#     forward_only = False #indicates whether we are in testing or training mode\n",
    "#     log_dir = 'logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data(seqs, labels, vocabsize, maxlen=None):\n",
    "    \"\"\"Create the matrices from the datasets.\n",
    "\n",
    "    This pad each sequence to the same lenght: the lenght of the\n",
    "    longuest sequence or maxlen.\n",
    "\n",
    "    if maxlen is set, we will cut all sequence to this maximum\n",
    "    lenght.\n",
    "\n",
    "    This swap the axis!\n",
    "    \"\"\"\n",
    "    # x: a list of sentences\n",
    "    lengths = [len(s) for s in seqs]\n",
    "\n",
    "    eventSeq = []\n",
    "\n",
    "    for seq in seqs:\n",
    "        t = []\n",
    "        for visit in seq:\n",
    "            t.extend(visit)\n",
    "        eventSeq.append(t)\n",
    "    eventLengths = [len(s) for s in eventSeq]\n",
    "\n",
    "    if maxlen is not None:\n",
    "        new_seqs = []\n",
    "        new_lengths = []\n",
    "        new_labels = []\n",
    "        for l, s, la in zip(lengths, seqs, labels):\n",
    "            if l < maxlen:\n",
    "                new_seqs.append(s)\n",
    "                new_lengths.append(l)\n",
    "                new_labels.append(la)\n",
    "            else:\n",
    "                new_seqs.append(s[:maxlen])\n",
    "                new_lengths.append(maxlen)\n",
    "                new_labels.append(la[:maxlen])\n",
    "        lengths = new_lengths\n",
    "        seqs = new_seqs\n",
    "        labels = new_labels\n",
    "\n",
    "        if len(lengths) < 1:\n",
    "            return None, None, None\n",
    "\n",
    "    n_samples = len(seqs)\n",
    "    maxlen = max(maxlen, np.max(lengths)) # changed this line to always to goto max_len as we use in pytroch with batches\n",
    "\n",
    "    x = np.zeros((n_samples, maxlen, vocabsize)).astype('int64')\n",
    "    x_mask = np.zeros((n_samples, maxlen)).astype(float)\n",
    "    y = np.ones((n_samples, maxlen)).astype(float)\n",
    "    for idx, s in enumerate(seqs):\n",
    "        x_mask[idx, :lengths[idx]] = 1\n",
    "        for j, sj in enumerate(s):\n",
    "            for tsj in sj:\n",
    "                x[idx, j, tsj - 1] = 1\n",
    "    for idx, t in enumerate(labels):\n",
    "        y[idx, :lengths[idx]] = t\n",
    "        # if lengths[idx] < maxlen:\n",
    "        #     y[idx,lengths[idx]:] = t[-1]\n",
    "    \n",
    "#     # randomly generated list of labels. for testing. note that this size is n_samples,1 and not n_samples,n_visits\n",
    "#     y = torch.randint(0, 2, (n_samples,)) #.astype(float)\n",
    "    return x, x_mask, y, lengths, eventLengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] load resource\\vocab.pkl\n",
      " [*] load resource/X_train.pkl\n",
      " [*] load resource/Y_train.pkl\n",
      " [*] load resource/X_valid.pkl\n",
      " [*] load resource/Y_valid.pkl\n",
      " [*] load resource/X_test.pkl\n",
      " [*] load resource/Y_test.pkl\n",
      "vocabulary size: 619\n",
      "number of training documents: 2000\n",
      "number of validation documents: 500\n",
      "number of testing documents: 500\n",
      "legth of dataset of dtype = train: 2000\n",
      "legth of dataset of dtype = valid: 500\n",
      "legth of dataset of dtype = test: 500\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, seqs, hfs):\n",
    "        self.x = seqs\n",
    "        self.y = hfs\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "    \n",
    "FLAGS = Config()\n",
    "data_sets = PatientReader(FLAGS)\n",
    "\n",
    "def get_custom_dataset(dtype):\n",
    "    \"\"\" dtype in train, valid, test\"\"\"\n",
    "    X_raw_data, Y_raw_data = data_sets.get_data_from_type(dtype)\n",
    "    dataset = CustomDataset(X_raw_data, Y_raw_data)\n",
    "    print(f\"legth of dataset of dtype = {dtype}:\", len(X_raw_data))\n",
    "    return dataset\n",
    "\n",
    "train_dataset = get_custom_dataset(\"train\")\n",
    "val_dataset = get_custom_dataset(\"valid\")\n",
    "test_dataset =get_custom_dataset(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "     Collate the the list of samples into batches. For each patient, you need to pad the diagnosis\n",
    "        sequences to the sample shape (max # visits, max # diagnosis codes). The padding infomation\n",
    "        is stored in `mask`.\n",
    "    \n",
    "    Arguments:\n",
    "        data: a list of samples fetched from `CustomDataset`\n",
    "        \n",
    "    Outputs:\n",
    "        x: a tensor of shape (# patiens, max # visits, max # diagnosis codes) of type torch.long\n",
    "        masks: a tensor of shape (# patiens, max # visits, max # diagnosis codes) of type torch.bool\n",
    "        rev_x: same as x but in reversed time. This will be used in our RNN model for masking \n",
    "        rev_masks: same as mask but in reversed time. This will be used in our RNN model for masking\n",
    "        y: a tensor of shape (# patiens) of type torch.float\n",
    "        \n",
    "    Note that you can obtains the list of diagnosis codes and the list of hf labels\n",
    "        using: `sequences, labels = zip(*data)`\n",
    "    \"\"\"\n",
    "\n",
    "    sequences, labels = zip(*data)\n",
    "\n",
    "    x, x_mask, y, lengths, eventLengths = prepare_data(seqs=sequences, labels=labels, vocabsize=FLAGS.vocab_size, maxlen=MAX_LENGTH)\n",
    "    \n",
    "    x = torch.tensor(x, dtype=torch.float)\n",
    "    x_mask = torch.tensor(x_mask, dtype=torch.bool)\n",
    "    y = torch.tensor(y, dtype=torch.float)\n",
    "\n",
    "    return x, x_mask, y, lengths, eventLengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data.dataset import random_split\n",
    "\n",
    "# split = int(len(dataset)*0.5)\n",
    "\n",
    "# lengths = [split, len(dataset) - split]\n",
    "# train_dataset, val_dataset = random_split(dataset, lengths)\n",
    "\n",
    "# print(\"Length of train dataset:\", len(train_dataset))\n",
    "# print(\"Length of val dataset:\", len(val_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def load_data(train_dataset, val_dataset,test_dataset, collate_fn,batch_size=128):\n",
    "    \n",
    "    '''\n",
    "    Implement this function to return the data loader for  train and validation dataset. \n",
    "    Set batchsize to batch_size. Set `shuffle=True` only for train dataloader.\n",
    "    \n",
    "    Arguments:\n",
    "        train dataset: train dataset of type `CustomDataset`\n",
    "        val dataset: validation dataset of type `CustomDataset`\n",
    "        test dataset: test dataset of type `CustomDataset`\n",
    "        \n",
    "        collate_fn: collate function\n",
    "        \n",
    "    Outputs:\n",
    "        train_loader, val_loader, test_dataset : train and validation and test dataloaders\n",
    "    \n",
    "    Note that you need to pass the collate function to the data loader `collate_fn()`.\n",
    "    '''\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = load_data(train_dataset, val_dataset,test_dataset, collate_fn,batch_size = N_BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_last_visit(hidden_states, masks):\n",
    "#     print(hidden_states.shape)  # torch.Size([32, 175, 256])\n",
    "\n",
    "#     print(masks.shape) #torch.Size([32, 175])\n",
    "#     \"\"\"\n",
    "#      obtain the hidden state for the last true visit (not padding visits)\n",
    "\n",
    "#     Arguments:\n",
    "#         hidden_states: the hidden states of each visit of shape (batch_size, # visits, embedding_dim)\n",
    "#         masks: the padding masks of shape (batch_size, # visits, # diagnosis codes)\n",
    "\n",
    "#     Outputs:\n",
    "#         last_hidden_state: the hidden state for the last true visit of shape (batch_size, embedding_dim)\n",
    "        \n",
    "#     NOTE: DO NOT use for loop.\n",
    "    \n",
    "#     HINT: First convert the mask to a vector of shape (batch_size,) containing the true visit length; \n",
    "#           and then use this length vector as index to select the last visit.\n",
    "#     \"\"\"\n",
    "\n",
    "    mask_length = masks.count_nonzero(dim=1)\n",
    "    return hidden_states[range(hidden_states.shape[0]),mask_length-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# input = torch.randn(batch_size, sequence_length, input_size)\n",
    "\n",
    "print_flag = False\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRUModel, self).__init__()\n",
    "\n",
    "        self.gru = nn.GRU(input_size=FLAGS.vocab_size, hidden_size=N_HIDDEN, batch_first=True)\n",
    "        self.fc = nn.Linear(in_features= N_HIDDEN, out_features=MAX_LENGTH)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, masks):\n",
    "        if print_flag: print( \"x\" ,x.shape)\n",
    "        if print_flag: print( \"masks\",masks.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        if print_flag: print( \"batch_size\", batch_size)\n",
    "        output, h_n = self.gru(x)\n",
    "        if print_flag: print( \"output\", output.shape)\n",
    "        if print_flag: print( \"h_n\", h_n.shape)\n",
    "        true_h_n = get_last_visit(output, masks)\n",
    "        if print_flag: print( \"true_h_n\",true_h_n.shape)\n",
    "        logits = self.fc(true_h_n)   \n",
    "        if print_flag: print( \"logits\",logits.shape)\n",
    "        probs = self.sigmoid(logits)\n",
    "        if print_flag: print( \"probs\",probs.shape)\n",
    "        probs_ret = probs.view((batch_size,-1))\n",
    "        if print_flag: print( \"probs_ret\",probs_ret.shape)\n",
    "        return probs_ret\n",
    "    \n",
    "## H0 defaults to zeros if not provided.\n",
    "#     def initHidden(self):\n",
    "#         return torch.zeros(1, N_HIDDEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRUModel(\n",
       "  (gru): GRU(619, 200, batch_first=True)\n",
       "  (fc): Linear(in_features=200, out_features=300, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_rnn = GRUModel()\n",
    "naive_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 300, 619]), torch.Size([128, 300]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter = iter(train_loader)\n",
    "x, x_mask, y, lengths, eventLengths = next(train_iter)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(naive_rnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "\n",
    "def eval_model(model, data_loader):\n",
    "    \n",
    "    \"\"\"\n",
    "    evaluate the model.\n",
    "    \n",
    "    Arguments:\n",
    "        model: the RNN model\n",
    "        val_loader: validation dataloader\n",
    "        \n",
    "    Outputs:\n",
    "        precision: overall precision score\n",
    "        recall: overall recall score\n",
    "        f1: overall f1 score\n",
    "        roc_auc: overall roc_auc score\n",
    "        \n",
    "    Note that please pass all four arguments to the model so that we can use this function for both \n",
    "    models. (Use `model(x, masks, rev_x, rev_masks)`.)\n",
    "        \n",
    "    HINT: checkout https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_score = torch.Tensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    model.eval()\n",
    "    for x, x_mask, y, lengths, eventLengths in data_loader:\n",
    "        y_hat = model(x, x_mask)\n",
    "        y_score = torch.cat((y_score,  y_hat.detach().to(device)), dim=0)\n",
    "        y_hat = (y_hat > 0.5).int()\n",
    "        y_pred = torch.cat((y_pred,  y_hat.detach().to(device)), dim=0)\n",
    "        y_true = torch.cat((y_true, y.detach().to(device)), dim=0)\n",
    "    \"\"\"\n",
    "        Calculate precision, recall, f1, and roc auc scores.\n",
    "        Use `average='binary'` for calculating precision, recall, and fscore.\n",
    "    \"\"\"\n",
    "#     print(y_pred.shape, y_true.shape)\n",
    "    p, r, f, _ = precision_recall_fscore_support(torch.flatten(y_true), (np.array(y_pred)>0.5).flatten(), average='binary')\n",
    "    roc_auc = roc_auc_score(torch.flatten(y_true), torch.flatten(y_score))\n",
    "    return p, r, f, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, n_epochs):\n",
    "    \"\"\"\n",
    "    train the model.\n",
    "    \n",
    "    Arguments:\n",
    "        model: the RNN model\n",
    "        train_loader: training dataloder\n",
    "        val_loader: validation dataloader\n",
    "        n_epochs: total number of epochs\n",
    "        \n",
    "    You need to call `eval_model()` at the end of each training epoch to see how well the model performs \n",
    "    on validation data.\n",
    "        \n",
    "    Note that please pass all four arguments to the model so that we can use this function for both \n",
    "    models. (Use `model(x, masks, rev_x, rev_masks)`.)\n",
    "    \"\"\"\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, x_mask, y, lengths, eventLengths in train_loader:\n",
    "            \"\"\"\n",
    "                1. zero grad\n",
    "                2. model forward\n",
    "                3. calculate loss\n",
    "                4. loss backward\n",
    "                5. optimizer step\n",
    "            \"\"\"\n",
    "            outputs = model(x, x_mask)\n",
    "#             print(\"outputs\",outputs.shape)\n",
    "#             print(\"y\",y.shape)\n",
    "            loss = criterion(outputs, y) \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        p, r, f, roc_auc = eval_model(model, val_loader)\n",
    "        print('Epoch: {} \\t Validation p: {:.2f}, r:{:.2f}, f: {:.2f}, roc_auc: {:.2f}'\n",
    "              .format(epoch+1, p, r, f, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Training Loss: 0.559083\n",
      "Epoch: 1 \t Validation p: 0.91, r:0.92, f: 0.92, roc_auc: 0.90\n",
      "Epoch: 2 \t Training Loss: 0.285555\n",
      "Epoch: 2 \t Validation p: 0.91, r:0.92, f: 0.92, roc_auc: 0.92\n",
      "Epoch: 3 \t Training Loss: 0.273508\n",
      "Epoch: 3 \t Validation p: 0.91, r:0.92, f: 0.92, roc_auc: 0.92\n",
      "Epoch: 4 \t Training Loss: 0.271554\n",
      "Epoch: 4 \t Validation p: 0.91, r:0.92, f: 0.92, roc_auc: 0.92\n",
      "Epoch: 5 \t Training Loss: 0.270376\n",
      "Epoch: 5 \t Validation p: 0.92, r:0.92, f: 0.92, roc_auc: 0.93\n",
      "Epoch: 6 \t Training Loss: 0.269131\n",
      "Epoch: 6 \t Validation p: 0.92, r:0.92, f: 0.92, roc_auc: 0.93\n"
     ]
    }
   ],
   "source": [
    "n_epochs = num_epochs\n",
    "train(naive_rnn, train_loader, val_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9260353617118455\n",
      "0.9255035281296328\n"
     ]
    }
   ],
   "source": [
    "p, r, f, roc_auc = eval_model(naive_rnn, val_loader)\n",
    "print(roc_auc)\n",
    "assert roc_auc > 0.7, \"ROC AUC is too low on the validation set (%f < 0.7)\"%(roc_auc)\n",
    "\n",
    "\n",
    "p, r, f, roc_auc = eval_model(naive_rnn, test_loader)\n",
    "print(roc_auc)\n",
    "assert roc_auc > 0.7, \"ROC AUC is too low on the test set (%f < 0.7)\"%(roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9219502761966419,\n",
       " 0.9222526871772444,\n",
       " 0.9221014568923833,\n",
       " 0.9255035281296328)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p, r, f, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognition Net  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RecognitionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RecognitionNet, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(1473, 64)\n",
    "        \n",
    "        l_in = lasagne.layers.InputLayer(shape=(N_BATCH, MAX_LENGTH, N_VOCAB))\n",
    "        l_in = nn.Sequential(\n",
    "            nn.Linear(in_features=N_VOCAB, out_features=N_VOCAB),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=N_VOCAB, out_features=MAX_LENGTH * N_VOCAB),\n",
    "            nn.Reshape(N_BATCH, MAX_LENGTH, N_VOCAB)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat gpt output\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ThetaLayer(nn.Module):\n",
    "    def __init__(self, mu_layer, logsigma_layer, maxlen):\n",
    "        super().__init__()\n",
    "        self.mu = mu_layer\n",
    "        self.logsigma = logsigma_layer\n",
    "        self.klterm = 0\n",
    "        self.theta = nn.Parameter(torch.zeros(1, logsigma_layer.out_features))\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def forward(self, x):\n",
    "        logsigma_in = self.logsigma(x[0])\n",
    "        mu_in = self.mu(x[1])\n",
    "        kltermFn = lambda logsigma, mu: 0.5 * (1 + logsigma * 2 - (mu ** 2) - torch.exp(logsigma) ** 2)\n",
    "        self.klterm = (0.5 * (1 + logsigma_in * 2) - (mu_in ** 2) - (torch.exp(logsigma_in) ** 2))\n",
    "        out = lambda mu, logsigma, input: (1 / (input * (torch.exp(logsigma) * (2 * np.pi) ** (1 / 2)))) * torch.exp(\n",
    "            -((torch.log(input) - mu) ** 2) / (2 * (torch.exp(logsigma) ** 2)))\n",
    "        self.theta = nn.Parameter(\n",
    "            out(mu_in, logsigma_in, x).reshape(x[0].size(0), self.maxlen, self.logsigma.out_features))\n",
    "        return self.theta\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class ExpressionLayer(nn.Module):\n",
    "    def __init__(self, expression, output_shape):\n",
    "        super(ExpressionLayer, self).__init__()\n",
    "        self.expression = expression\n",
    "        self.output_shape_ = output_shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.expression(x)\n",
    "\n",
    "    def output_shape(self, input_shape):\n",
    "        return (input_shape[0],) + self.output_shape_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Chat gpt output\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, num_topics, max_length):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.l_in = nn.Linear(num_inputs, num_hidden)\n",
    "        self.l_1 = nn.Linear(num_hidden, N_HIDDEN)\n",
    "        self.l_2 = nn.Linear(N_HIDDEN, N_HIDDEN)\n",
    "        self.mu = nn.Linear(N_HIDDEN, n_topics)\n",
    "        self.log_sigma = nn.Linear(N_HIDDEN, n_topics)\n",
    "        self.l_theta = ThetaLayer([self.mu, self.log_sigma], maxlen=MAX_LENGTH) \n",
    "        \n",
    "        self.l_B = nn.Linear(num_inputs, n_topics)\n",
    "        self.l_context = nn.Multiplication()\n",
    "        \n",
    "        #####\n",
    "        #####\n",
    "        #### Yiming at 2023-04-09 HUGE BUG!!!!\n",
    "        self.l_context = nn.Lambda(lambda X: torch.mean(X, dim=-1))\n",
    "        \n",
    "        self.l_forward0 = nn.Linear(num_hidden, 1)\n",
    "        self.l_dense0 = nn.Linear(num_hidden, 1)\n",
    "        self.l_dense1 = nn.Flatten()\n",
    "        self.l_dense = nn.Add()\n",
    "        self.l_out0 = nn.Sigmoid()\n",
    "        self.l_out = nn.Lambda(lambda X: X + 0.000001)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # Compute the network's forward pass\n",
    "        l_in = self.l_in(x)\n",
    "        l_1 = nn.ReLU()(l_in)\n",
    "        l_2 = nn.ReLU()(l_1)\n",
    "        mu = self.mu(l_2)\n",
    "        log_sigma = self.log_sigma(l_2)\n",
    "        l_theta = ThetaLayer([mu, log_sigma], maxlen=MAX_LENGTH) \n",
    "\n",
    "        l_B = self.l_B(x)\n",
    "        l_context = self.l_context([l_B, l_theta])\n",
    "        \n",
    "        l_forward0 = self.l_forward0(l_2)\n",
    "        l_dense0 = self.l_dense0(l_2)\n",
    "        l_dense1 = self.l_dense1(l_forward0)\n",
    "        l_dense = self.l_dense([l_dense1, l_context])\n",
    "        l_out0 = self.l_out0(l_dense)\n",
    "        l_out = self.l_out([l_out0, mask])\n",
    "        \n",
    "        return l_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The CONTENT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONTENT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CONTENT, self).__init__()\n",
    "        \n",
    "        self.gru = GRUModel()\n",
    "        self.recog = RecognitionNet()\n",
    "        self.log_reg = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gru_out = self.gru(x)\n",
    "        recog_out = self.recog(x)\n",
    "        z_out =  W * gru_out + B * recog_out\n",
    "        z_out = self.linear(z_out)\n",
    "        y_pred = torch.sigmoid(z_out)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lasagne' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m content_model \u001B[38;5;241m=\u001B[39m \u001B[43mCONTENT\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[29], line 6\u001B[0m, in \u001B[0;36mCONTENT.__init__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28msuper\u001B[39m(CONTENT, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgru \u001B[38;5;241m=\u001B[39m GRUModel()\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecog \u001B[38;5;241m=\u001B[39m \u001B[43mRecognitionNet\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog_reg \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mLinear(input_dim, output_dim)\n",
      "Cell \u001B[1;32mIn[24], line 7\u001B[0m, in \u001B[0;36mRecognitionNet.__init__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28msuper\u001B[39m(RecognitionNet, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc1 \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mLinear(\u001B[38;5;241m1473\u001B[39m, \u001B[38;5;241m64\u001B[39m)\n\u001B[1;32m----> 7\u001B[0m l_in \u001B[38;5;241m=\u001B[39m \u001B[43mlasagne\u001B[49m\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mInputLayer(shape\u001B[38;5;241m=\u001B[39m(N_BATCH, MAX_LENGTH, N_VOCAB))\n\u001B[0;32m      8\u001B[0m l_in \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mSequential(\n\u001B[0;32m      9\u001B[0m     nn\u001B[38;5;241m.\u001B[39mLinear(in_features\u001B[38;5;241m=\u001B[39mN_VOCAB, out_features\u001B[38;5;241m=\u001B[39mN_VOCAB),\n\u001B[0;32m     10\u001B[0m     nn\u001B[38;5;241m.\u001B[39mDropout(p\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m),\n\u001B[0;32m     11\u001B[0m     nn\u001B[38;5;241m.\u001B[39mLinear(in_features\u001B[38;5;241m=\u001B[39mN_VOCAB, out_features\u001B[38;5;241m=\u001B[39mMAX_LENGTH \u001B[38;5;241m*\u001B[39m N_VOCAB),\n\u001B[0;32m     12\u001B[0m     nn\u001B[38;5;241m.\u001B[39mReshape(N_BATCH, MAX_LENGTH, N_VOCAB)\n\u001B[0;32m     13\u001B[0m )\n",
      "\u001B[1;31mNameError\u001B[0m: name 'lasagne' is not defined"
     ]
    }
   ],
   "source": [
    "content_model = CONTENT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'content_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mBCELoss()\n\u001B[0;32m      2\u001B[0m learning_rate \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.001\u001B[39m\n\u001B[1;32m----> 3\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(\u001B[43mcontent_model\u001B[49m\u001B[38;5;241m.\u001B[39mparameters(),lr\u001B[38;5;241m=\u001B[39mlearning_rate)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'content_model' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(content_model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# chatgpt output\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ThetaLayer(nn.Module):\n",
    "    def __init__(self, mu, log_sigma, maxlen):\n",
    "        super(ThetaLayer, self).__init__()\n",
    "        self.mu = mu\n",
    "        self.log_sigma = log_sigma\n",
    "        self.maxlen = maxlen\n",
    "        self.klterm = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mu = F.dropout(self.mu, p=0.5, training=self.training)\n",
    "        self.log_sigma = F.dropout(self.log_sigma, p=0.5, training=self.training)\n",
    "        epsilon = torch.randn(self.mu.size(), device=x.device)\n",
    "        z = self.mu + torch.exp(self.log_sigma / 2) * epsilon\n",
    "        self.klterm = -0.5 * torch.mean(\n",
    "            torch.sum(1 + 2 * self.log_sigma - self.mu.pow(2) - torch.exp(2 * self.log_sigma), dim=2), dim=1)\n",
    "        theta = F.pad(z, (0, self.maxlen - z.size()[1], 0, 0))\n",
    "        return theta\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, n_hidden, n_topics, maxlen):\n",
    "        super(Model, self).__init__()\n",
    "        self.embed = nn.Linear(vocab_size, embed_size, bias=False)\n",
    "        self.gru = nn.GRU(embed_size, n_hidden, bidirectional=False, batch_first=True)\n",
    "        self.dense1 = nn.Linear(vocab_size, n_hidden)\n",
    "        self.dense2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.mu = nn.Linear(n_hidden, n_topics)\n",
    "        self.log_sigma = nn.Linear(n_hidden, n_topics)\n",
    "        self.theta = ThetaLayer(None, None, maxlen)\n",
    "        self.B = nn.Linear(vocab_size, n_topics, bias=False)\n",
    "        self.context = nn.Sequential(nn.Linear(n_topics, 1, bias=False), nn.Flatten(1))\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x_embed = self.embed(x)\n",
    "        h, _ = self.gru(x_embed)\n",
    "        h_masked = h * mask[:, :, None]\n",
    "        h_masked = h_masked.reshape((-1, h_masked.size()[2]))\n",
    "        h1 = F.relu(self.dense1(x))\n",
    "        h2 = F.relu(self.dense2(h1))\n",
    "        mu = self.mu(h2)\n",
    "        log_sigma = self.log_sigma(h2)\n",
    "        theta = self.theta(x)\n",
    "        B = self.B(x)\n",
    "        context = self.context(B)\n",
    "        dense = self.context(h_masked) + context.unsqueeze(1)\n",
    "        out0 = torch.sigmoid(dense)\n",
    "        out = out0 * mask[:, :, None] + 0.000001\n",
    "        return out\n",
    "\n",
    "# Define hyperparameters\n",
    "N_BATCH = 1\n",
    "MAX_LENGTH = 100\n",
    "N_VOCAB = 10000\n",
    "EMBED_SIZE = 100\n",
    "N_HIDDEN = 256\n",
    "N_TOPICS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Define model and optimizer\n",
    "model = Model(N_VOCAB, EMBED_SIZE, N_HIDDEN, N_TOPICS, MAX_LENGTH)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Define training function\n",
    "def train_fn(input_var, target_values, mask_var):\n",
    "    optimizer.zero_grad()\n",
    "    input_tensor = torch.tensor(input_var, dtype=torch.float32)\n",
    "    target_tensor = torch.tensor(target_values, dtype=torch.float32)\n",
    "    mask_tensor = torch.tensor(mask_var, dtype=torch.float32)\n",
    "    output = model(input_tensor, mask_tensor)\n",
    "   \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# chat gpt output\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# define the model architecture\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.rnn(x)[0]\n",
    "        x = x * mask.unsqueeze(-1)\n",
    "        x = x.sum(dim=1) / mask.sum(dim=1).unsqueeze(-1)\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# define the training function\n",
    "def train(model, optimizer, criterion, x, y, mask):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x, mask)\n",
    "    loss = criterion(output.flatten(), y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# define the function to compute cost\n",
    "def compute_cost(model, x, y, mask):\n",
    "    output = model(x, mask)\n",
    "    loss = nn.BCELoss()(output.flatten(), y)\n",
    "    return loss.item()\n",
    "\n",
    "# define the function to output the hidden state\n",
    "def output_theta(model, x, mask):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        output, hn = model.rnn(x)\n",
    "        output = output * mask.unsqueeze(-1)\n",
    "        output = output.sum(dim=1) / mask.sum(dim=1).unsqueeze(-1)\n",
    "    return hn.detach().numpy().reshape(x.shape[0], -1), output.detach().numpy()\n",
    "\n",
    "# define the function to iterate through minibatches\n",
    "def iterate_minibatches_listinputs(inputs_list, batch_size, shuffle=False):\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs_list[0]))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs_list[0]), batch_size):\n",
    "        end_idx = start_idx + batch_size\n",
    "        if end_idx > len(inputs_list[0]):\n",
    "            end_idx = len(inputs_list[0])\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:end_idx]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, end_idx)\n",
    "        yield [torch.from_numpy(inputs[excerpt]).float() for inputs in inputs_list]\n",
    "\n",
    "# set the seed for reproducibility\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# load the data\n",
    "trainingAdmiSeqs = np.load(\"trainingAdmiSeqs.npy\")\n",
    "trainingLabels = np.load(\"trainingLabels.npy\")\n",
    "trainingMask = np.load(\"trainingMask.npy\")\n",
    "test_admiSeqs = np.load(\"test_admiSeqs.npy\")\n",
    "test_labels = np.load(\"test_labels.npy\")\n",
    "test_mask = np.load(\"test_mask.npy\")\n",
    "testLengths = np.load(\"testLengths.npy\")\n",
    "\n",
    "# set the hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "input_dim = trainingAdmiSeqs.shape[-1]\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "lr = 0.001\n",
    "\n",
    "# create the model, optimizer and criterion\n",
    "model = Model(input_dim, hidden_dim, output_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# train the model\n",
    "for epoch in range(num_epochs):\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "   "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat gpt output\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# define the model architecture\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.rnn(x)[0]\n",
    "        x = x * mask.unsqueeze(-1)\n",
    "        x = x.sum(dim=1) / mask.sum(dim=1).unsqueeze(-1)\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# define the training function\n",
    "def train(model, optimizer, criterion, x, y, mask):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x, mask)\n",
    "    loss = criterion(output.flatten(), y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# define the function to compute cost\n",
    "def compute_cost(model, x, y, mask):\n",
    "    output = model(x, mask)\n",
    "    loss = nn.BCELoss()(output.flatten(), y)\n",
    "    return loss.item()\n",
    "\n",
    "# define the function to output the hidden state\n",
    "def output_theta(model, x, mask):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        output, hn = model.rnn(x)\n",
    "        output = output * mask.unsqueeze(-1)\n",
    "        output = output.sum(dim=1) / mask.sum(dim=1).unsqueeze(-1)\n",
    "    return hn.detach().numpy().reshape(x.shape[0], -1), output.detach().numpy()\n",
    "\n",
    "# define the function to iterate through minibatches\n",
    "def iterate_minibatches_listinputs(inputs_list, batch_size, shuffle=False):\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs_list[0]))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs_list[0]), batch_size):\n",
    "        end_idx = start_idx + batch_size\n",
    "        if end_idx > len(inputs_list[0]):\n",
    "            end_idx = len(inputs_list[0])\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:end_idx]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, end_idx)\n",
    "        yield [torch.from_numpy(inputs[excerpt]).float() for inputs in inputs_list]\n",
    "\n",
    "# set the seed for reproducibility\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# load the data\n",
    "trainingAdmiSeqs = np.load(\"trainingAdmiSeqs.npy\")\n",
    "trainingLabels = np.load(\"trainingLabels.npy\")\n",
    "trainingMask = np.load(\"trainingMask.npy\")\n",
    "test_admiSeqs = np.load(\"test_admiSeqs.npy\")\n",
    "test_labels = np.load(\"test_labels.npy\")\n",
    "test_mask = np.load(\"test_mask.npy\")\n",
    "testLengths = np.load(\"testLengths.npy\")\n",
    "\n",
    "# set the hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "input_dim = trainingAdmiSeqs.shape[-1]\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "lr = 0.001\n",
    "\n",
    "# create the model, optimizer and criterion\n",
    "model = Model(input_dim, hidden_dim, output_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# train the model\n",
    "for epoch in range(num_epochs):\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}