{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from config import Config\n",
    "from patient_data_reader import PatientReader\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of units in the hidden (recurrent) layer\n",
    "N_HIDDEN = 200\n",
    "# Number of training sequences in each batch\n",
    "\n",
    "\n",
    "# All gradients above this will be clipped\n",
    "GRAD_CLIP = 100\n",
    "# How often should we check the output?\n",
    "EPOCH_SIZE = 100\n",
    "# Number of epochs to train the net\n",
    "num_epochs = 6\n",
    "\n",
    "MAX_LENGTH = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(seqs, labels, vocabsize, maxlen=None):\n",
    "    \"\"\"Create the matrices from the datasets.\n",
    "\n",
    "    This pad each sequence to the same lenght: the lenght of the\n",
    "    longuest sequence or maxlen.\n",
    "\n",
    "    if maxlen is set, we will cut all sequence to this maximum\n",
    "    lenght.\n",
    "\n",
    "    This swap the axis!\n",
    "    \"\"\"\n",
    "    # x: a list of sentences\n",
    "    lengths = [len(s) for s in seqs]\n",
    "\n",
    "    eventSeq = []\n",
    "\n",
    "    for seq in seqs:\n",
    "        t = []\n",
    "        for visit in seq:\n",
    "            t.extend(visit)\n",
    "        eventSeq.append(t)\n",
    "    eventLengths = [len(s) for s in eventSeq]\n",
    "\n",
    "    if maxlen is not None:\n",
    "        new_seqs = []\n",
    "        new_lengths = []\n",
    "        new_labels = []\n",
    "        for l, s, la in zip(lengths, seqs, labels):\n",
    "            if l < maxlen:\n",
    "                new_seqs.append(s)\n",
    "                new_lengths.append(l)\n",
    "                new_labels.append(la)\n",
    "            else:\n",
    "                new_seqs.append(s[:maxlen])\n",
    "                new_lengths.append(maxlen)\n",
    "                new_labels.append(la[:maxlen])\n",
    "        lengths = new_lengths\n",
    "        seqs = new_seqs\n",
    "        labels = new_labels\n",
    "\n",
    "        if len(lengths) < 1:\n",
    "            return None, None, None\n",
    "\n",
    "    n_samples = len(seqs)\n",
    "    maxlen = np.max(lengths)\n",
    "\n",
    "    x = np.zeros((n_samples, maxlen, vocabsize)).astype('int64')\n",
    "    x_mask = np.zeros((n_samples, maxlen)).astype(float)\n",
    "    y = np.ones((n_samples, maxlen)).astype(float)\n",
    "    for idx, s in enumerate(seqs):\n",
    "        x_mask[idx, :lengths[idx]] = 1\n",
    "        for j, sj in enumerate(s):\n",
    "            for tsj in sj:\n",
    "                x[idx, j, tsj - 1] = 1\n",
    "    for idx, t in enumerate(labels):\n",
    "        y[idx, :lengths[idx]] = t\n",
    "        # if lengths[idx] < maxlen:\n",
    "        #     y[idx,lengths[idx]:] = t[-1]\n",
    "\n",
    "    return x, x_mask, y, lengths, eventLengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] load resource\\vocab.pkl\n",
      " [*] load resource/X_train.pkl\n",
      " [*] load resource/Y_train.pkl\n",
      " [*] load resource/X_valid.pkl\n",
      " [*] load resource/Y_valid.pkl\n",
      " [*] load resource/X_test.pkl\n",
      " [*] load resource/Y_test.pkl\n",
      "vocabulary size: 619\n",
      "number of training documents: 2000\n",
      "number of validation documents: 500\n",
      "number of testing documents: 500\n",
      "239887\n",
      "685482\n"
     ]
    }
   ],
   "source": [
    "FLAGS = Config()\n",
    "data_sets = PatientReader(FLAGS)\n",
    "\n",
    "X_raw_data, Y_raw_data = data_sets.get_data_from_type(\"train\")\n",
    "trainingAdmiSeqs, trainingMask, trainingLabels, trainingLengths, ltr = prepare_data(X_raw_data, Y_raw_data,\n",
    "                                                                                    vocabsize=619,\n",
    "                                                                                    maxlen=MAX_LENGTH)\n",
    "Num_Samples, MAX_LENGTH, N_VOCAB = trainingAdmiSeqs.shape\n",
    "\n",
    "X_valid_data, Y_valid_data = data_sets.get_data_from_type(\"valid\")\n",
    "validAdmiSeqs, validMask, validLabels, validLengths, lval = prepare_data(X_valid_data, Y_valid_data, vocabsize=619,\n",
    "                                                                         maxlen=MAX_LENGTH)\n",
    "\n",
    "X_test_data, Y_test_data = data_sets.get_data_from_type(\"test\")\n",
    "test_admiSeqs, test_mask, test_labels, testLengths, ltes = prepare_data(X_test_data, Y_test_data, vocabsize=619,\n",
    "                                                                        maxlen=MAX_LENGTH)\n",
    "alllength = sum(trainingLengths) + sum(validLengths) + sum(testLengths)\n",
    "print(alllength)\n",
    "eventNum = sum(ltr) + sum(lval) + sum(ltes)\n",
    "print(eventNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingLabels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "619"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingMask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_raw_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw_data, Y_raw_data = data_sets.get_data_from_type(\"train\")\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, seqs, hfs):\n",
    "        self.x = seqs\n",
    "        self.y = hfs\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "    \n",
    "dataset = CustomDataset(X_raw_data, Y_raw_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "    TODO: Collate the the list of samples into batches. For each patient, you need to pad the diagnosis\n",
    "        sequences to the sample shape (max # visits, max # diagnosis codes). The padding infomation\n",
    "        is stored in `mask`.\n",
    "    \n",
    "    Arguments:\n",
    "        data: a list of samples fetched from `CustomDataset`\n",
    "        \n",
    "    Outputs:\n",
    "        x: a tensor of shape (# patiens, max # visits, max # diagnosis codes) of type torch.long\n",
    "        masks: a tensor of shape (# patiens, max # visits, max # diagnosis codes) of type torch.bool\n",
    "        rev_x: same as x but in reversed time. This will be used in our RNN model for masking \n",
    "        rev_masks: same as mask but in reversed time. This will be used in our RNN model for masking\n",
    "        y: a tensor of shape (# patiens) of type torch.float\n",
    "        \n",
    "    Note that you can obtains the list of diagnosis codes and the list of hf labels\n",
    "        using: `sequences, labels = zip(*data)`\n",
    "    \"\"\"\n",
    "\n",
    "    sequences, labels = zip(*data)\n",
    "\n",
    "    x, x_mask, y, lengths, eventLengths = prepare_data(seqs=sequences, labels=labels, vocabsize=619, maxlen=None)\n",
    "    \n",
    "    x = torch.from_numpy(x)\n",
    "    x_mask = torch.from_numpy(x_mask)\n",
    "    y = torch.from_numpy(y)\n",
    "    return x, x_mask, y, lengths, eventLengths\n",
    "    \n",
    "#     y = torch.tensor(labels, dtype=torch.float)\n",
    "    \n",
    "#     num_patients = len(sequences)\n",
    "#     num_visits = [len(patient) for patient in sequences]\n",
    "#     num_codes = [len(visit) for patient in sequences for visit in patient]\n",
    "\n",
    "#     max_num_visits = max(num_visits)\n",
    "#     max_num_codes = max(num_codes)\n",
    "    \n",
    "#     x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n",
    "#     rev_x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n",
    "#     masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n",
    "#     rev_masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n",
    "#     for i_patient, patient in enumerate(sequences):\n",
    "#         v = len(patient)\n",
    "#         for j_visit, visit in enumerate(patient):\n",
    "#             \"\"\"\n",
    "#             TODO: update `x`, `rev_x`, `masks`, and `rev_masks`\n",
    "#             \"\"\"\n",
    "#             # your code here\n",
    "# #             raise NotImplementedError\n",
    "#             l = len(visit)\n",
    "#             x[i_patient, j_visit, :l] = torch.tensor(visit, dtype=torch.long)\n",
    "#             masks[i_patient, j_visit, :l].fill_(1)\n",
    "#             # print(v-j_visit)\n",
    "#             rev_x[i_patient, v-j_visit-1, :l] = torch.tensor(visit, dtype=torch.long)\n",
    "#             rev_masks[i_patient, v-j_visit-1, :l].fill_(1)    \n",
    "    \n",
    "#     return x, masks, rev_x, rev_masks, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 1600\n",
      "Length of val dataset: 400\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "split = int(len(dataset)*0.8)\n",
    "\n",
    "lengths = [split, len(dataset) - split]\n",
    "train_dataset, val_dataset = random_split(dataset, lengths)\n",
    "\n",
    "print(\"Length of train dataset:\", len(train_dataset))\n",
    "print(\"Length of val dataset:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def load_data(train_dataset, val_dataset, collate_fn):\n",
    "    \n",
    "    '''\n",
    "    TODO: Implement this function to return the data loader for  train and validation dataset. \n",
    "    Set batchsize to 32. Set `shuffle=True` only for train dataloader.\n",
    "    \n",
    "    Arguments:\n",
    "        train dataset: train dataset of type `CustomDataset`\n",
    "        val dataset: validation dataset of type `CustomDataset`\n",
    "        collate_fn: collate function\n",
    "        \n",
    "    Outputs:\n",
    "        train_loader, val_loader: train and validation dataloaders\n",
    "    \n",
    "    Note that you need to pass the collate function to the data loader `collate_fn()`.\n",
    "    '''\n",
    "    \n",
    "    batch_size=32\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "train_loader, val_loader = load_data(train_dataset, val_dataset, collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# loader_iter = iter(train_loader)\n",
    "x, x_mask, y, lengths, eventLengths = next(loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 177, 619)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 177)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 177)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_visit(hidden_states, masks):\n",
    "    \"\"\"\n",
    "    TODO: obtain the hidden state for the last true visit (not padding visits)\n",
    "\n",
    "    Arguments:\n",
    "        hidden_states: the hidden states of each visit of shape (batch_size, # visits, embedding_dim)\n",
    "        masks: the padding masks of shape (batch_size, # visits, # diagnosis codes)\n",
    "\n",
    "    Outputs:\n",
    "        last_hidden_state: the hidden state for the last true visit of shape (batch_size, embedding_dim)\n",
    "        \n",
    "    NOTE: DO NOT use for loop.\n",
    "    \n",
    "    HINT: First convert the mask to a vector of shape (batch_size,) containing the true visit length; \n",
    "          and then use this length vector as index to select the last visit.\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    # raise NotImplementedError\n",
    "    sum_masks = masks.sum(axis = 2)\n",
    "    lens = ((sum_masks > 0).sum(axis = 1) - 1) \n",
    "    lens = lens.unsqueeze(-1)\n",
    "    indices = lens.repeat(1, hidden_states.shape[2])\n",
    "    indices = indices.unsqueeze(1)\n",
    "    # print(hidden_states.shape, masks.shape, sum_masks.shape, lens.shape, indices.shape)\n",
    "\n",
    "    last_visit = torch.gather(hidden_states, 1, indices)\n",
    "    last_visit = last_visit.squeeze(1)\n",
    "    \n",
    "    return last_visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = torch.randn(batch_size, sequence_length, input_size)\n",
    "\n",
    "input_size = 619\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRUModel, self).__init__()\n",
    "\n",
    "        self.gru = nn.GRU(input_size=619, hidden_size=256, batch_first=True)\n",
    "        self.fc = self.fc = nn.Linear(in_features= 256, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, masks):\n",
    "        \n",
    "        # 3. Pass the embegginds through the RNN layer;\n",
    "        output, h_n = self.gru(x)\n",
    "        # 4. Obtain the hidden state at the last visit.\n",
    "        true_h_n = get_last_visit(output, masks)\n",
    "        \n",
    "        output, hidden = self.gru(input, hidden)\n",
    "        logits = self.fc(true_h_n)        \n",
    "        probs = self.sigmoid(logits)\n",
    "        return probs.view(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRUModel(\n",
       "  (gru): GRU(619, 256, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_rnn = GRUModel()\n",
    "naive_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(naive_rnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "\n",
    "def eval_model(model, val_loader):\n",
    "    \n",
    "    \"\"\"\n",
    "    TODO: evaluate the model.\n",
    "    \n",
    "    Arguments:\n",
    "        model: the RNN model\n",
    "        val_loader: validation dataloader\n",
    "        \n",
    "    Outputs:\n",
    "        precision: overall precision score\n",
    "        recall: overall recall score\n",
    "        f1: overall f1 score\n",
    "        roc_auc: overall roc_auc score\n",
    "        \n",
    "    Note that please pass all four arguments to the model so that we can use this function for both \n",
    "    models. (Use `model(x, masks, rev_x, rev_masks)`.)\n",
    "        \n",
    "    HINT: checkout https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_score = torch.Tensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    model.eval()\n",
    "    for x, x_mask, y, lengths, eventLengths in val_loader:\n",
    "        y_hat = model(x, x_mask)\n",
    "        y_score = torch.cat((y_score,  y_hat.detach().to('cpu')), dim=0)\n",
    "        y_hat = (y_hat > 0.5).int()\n",
    "        y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
    "        y_true = torch.cat((y_true, y.detach().to('cpu')), dim=0)\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "        Calculate precision, recall, f1, and roc auc scores.\n",
    "        Use `average='binary'` for calculating precision, recall, and fscore.\n",
    "    \"\"\"\n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true, np.array(y_pred)>0.5, average='binary')\n",
    "    roc_auc = roc_auc_score(y_true, y_score)\n",
    "#     p, r, f, roc_auc = None, None, None, None\n",
    "    # your code here\n",
    "#     raise NotImplementedError\n",
    "    return p, r, f, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, n_epochs):\n",
    "    \"\"\"\n",
    "    TODO: train the model.\n",
    "    \n",
    "    Arguments:\n",
    "        model: the RNN model\n",
    "        train_loader: training dataloder\n",
    "        val_loader: validation dataloader\n",
    "        n_epochs: total number of epochs\n",
    "        \n",
    "    You need to call `eval_model()` at the end of each training epoch to see how well the model performs \n",
    "    on validation data.\n",
    "        \n",
    "    Note that please pass all four arguments to the model so that we can use this function for both \n",
    "    models. (Use `model(x, masks, rev_x, rev_masks)`.)\n",
    "    \"\"\"\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, x_mask, y, lengths, eventLengths in train_loader:\n",
    "            \"\"\"\n",
    "            TODO:\n",
    "                1. zero grad\n",
    "                2. model forward\n",
    "                3. calculate loss\n",
    "                4. loss backward\n",
    "                5. optimizer step\n",
    "            \"\"\"\n",
    "#             loss = None\n",
    "            outputs = model(x, x_mask)\n",
    "            loss = criterion(outputs, y) \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#             # your code here\n",
    "#             raise NotImplementedError\n",
    "            train_loss += loss.item()\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        p, r, f, roc_auc = eval_model(model, val_loader)\n",
    "        print('Epoch: {} \\t Validation p: {:.2f}, r:{:.2f}, f: {:.2f}, roc_auc: {:.2f}'\n",
    "              .format(epoch+1, p, r, f, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnaive_rnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[106], line 31\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, n_epochs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;250m            \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m            TODO:\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m                1. zero grad\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m                5. optimizer step\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m            \"\"\"\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#             loss = None\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m             outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m             loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y) \n\u001b[0;32m     33\u001b[0m             \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[102], line 16\u001b[0m, in \u001b[0;36mGRUModel.forward\u001b[1;34m(self, x, masks)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, masks):\n\u001b[0;32m     14\u001b[0m     \n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# 3. Pass the embegginds through the RNN layer;\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     output, h_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# 4. Obtain the hidden state at the last visit.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     true_h_n \u001b[38;5;241m=\u001b[39m get_last_visit(output, masks)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:998\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 998\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1001\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m   1002\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "train(naive_rnn, train_loader, val_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecognitionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(1473, 64)\n",
    "        \n",
    "        l_in = lasagne.layers.InputLayer(shape=(N_BATCH, MAX_LENGTH, N_VOCAB))\n",
    "        l_in = nn.Sequential(\n",
    "            nn.Linear(in_features=N_VOCAB, out_features=N_VOCAB),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=N_VOCAB, out_features=MAX_LENGTH * N_VOCAB),\n",
    "            nn.Reshape(N_BATCH, MAX_LENGTH, N_VOCAB)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
